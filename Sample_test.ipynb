{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdeba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from utils import add_logging_arguments\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "import imageio\n",
    "# import pygifsicle\n",
    "# import lpips\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "# from skimage.metrics import peak_signal_noise_ratio as compute_psnr\n",
    "import shutil\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = lambda: None\n",
    "args.gpu = 0 # gpu_id\n",
    "args.angular = 7 # number of angular views to generate; changing this will affect quantitative evaluation\n",
    "args.model = 'unet_icip'\n",
    "args.disp_model = 'dispnetC'\n",
    "args.flow_model = 'flownetC'\n",
    "args.display = 'multilayer'\n",
    "\n",
    "args.layers = 3\n",
    "args.rank = 12\n",
    "args.restore_file = 'weights/checkpoint_last.pt'\n",
    "\n",
    "\n",
    "args.dataset = 'test_st' # dataloader specifically for case without GT LF images\n",
    "args.h5_file = 'S3D_test10.h5'\n",
    "args.data_path = '/data/prasan/datasets/lfv_testFiles/S3D'\n",
    "args.batch_size = 1\n",
    "args.save_dir = 'results'\n",
    "args.shift = 10\n",
    "\n",
    "args.inph = 270\n",
    "args.inpw = 480 - args.shift\n",
    "args.seq_len = 4\n",
    "\n",
    "args.seed = 42\n",
    "args.dry_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(inputs, outputs):\n",
    "    inputs['video'] = inputs['video'].to(device)\n",
    "    inputs['lf_states'] = None\n",
    "    inputs['prev_idx'] = 0\n",
    "    inputs['curr_step'] = 0\n",
    "    outputs['pred_lf'] = []\n",
    "\n",
    "    for t in range(1, inputs['video'].size(1)):\n",
    "        # iterate over the t \\in T frames\n",
    "        if t > 0:\n",
    "            inputs['flow_loss'] = True\n",
    "            inputs['prev_idx'] = int(t - 1)\n",
    "        inputs['curr_step'] = t\n",
    "        run_instance(inputs, outputs)\n",
    "\n",
    "def run_instance(inputs, outputs):\n",
    "    # [N,2,2,3,H,W]: targets\n",
    "    # [batch, time, view, rgb, height, width]\n",
    "    targets = inputs['video'][:, inputs['prev_idx']:inputs['curr_step'] + 1, ...]\n",
    "    curr_gt_lf_frame = targets[:, -1, ...]\n",
    "    curr_stereo_frame = curr_gt_lf_frame[:, lf_view_idx, ...]\n",
    "    instance_loss = 0.\n",
    "\n",
    "    # from the same function return the disparity map\n",
    "    decomposition = lf_model(curr_stereo_frame, inputs)\n",
    "    # decomposition is of size [N,layers,rank,3,h,w]\n",
    "    curr_lf = tensor_display(decomposition)\n",
    "#     curr_lf = (curr_lf - torch.min(curr_lf))/(torch.maximum(curr_lf) - torch.min(curr_lf))\n",
    "#     curr_lf = curr_lf.clamp(0., 1.)\n",
    "    outputs['pred_lf'].append(curr_lf)\n",
    "\n",
    "    # compute the psnr, ssim and lpips values and update\n",
    "#     compute_lpips_ssim_psnr(\n",
    "#         outputs['pred_lf'][-1], curr_gt_lf_frame, outputs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46de8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    f'cuda:{args.gpu}') if torch.cuda.is_available() else torch.device('cpu')\n",
    "utils.setup_experiment(args)\n",
    "utils.init_logging(args)\n",
    "\n",
    "# indices of the input stereo frame in the output LF\n",
    "left_view_idx = 0#int(args.angular * (args.angular // 2))\n",
    "right_view_idx = 1#int(left_view_idx + (args.angular - 1))\n",
    "\n",
    "# this is the view indices for the network to predict LF\n",
    "lf_view_idx = [left_view_idx, right_view_idx]\n",
    "print(f'using stereo view indices as {lf_view_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = []\n",
    "trainable_params = []\n",
    "# ============== Initialize all network models ===================\n",
    "# initialize the lf prediction network V\n",
    "lf_model = models.build_model(\n",
    "    args.model,\n",
    "    n_channels=len(lf_view_idx) * 3,\n",
    "    args=args).to(device)\n",
    "trainable_params.extend(list(lf_model.parameters()))\n",
    "models_list.append(lf_model)\n",
    "\n",
    "# initialize the optical flow prediction network O\n",
    "flow_model = models.build_model(\n",
    "    args.flow_model,\n",
    "    n_channels=3,\n",
    "    args=args).to(device)\n",
    "trainable_params.extend(list(flow_model.parameters()))\n",
    "models_list.append(flow_model)\n",
    "\n",
    "# initialize the disparity map prediction network D\n",
    "disp_model = models.build_model(\n",
    "    args.disp_model,\n",
    "    n_channels=3,\n",
    "    args=args).to(device)\n",
    "trainable_params.extend(list(disp_model.parameters()))\n",
    "models_list.append(disp_model)\n",
    "\n",
    "optimizer = None#torch.optim.AdamW(trainable_params, lr=args.lr)\n",
    "scheduler = None#torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=args.patience, min_lr=1e-6)\n",
    "logging.info(\n",
    "    f\"Built {len(models_list)} models consisting of {sum(p.numel() for p in trainable_params):,} parameters\")\n",
    "\n",
    "# ========== Initialize the low-rank display model ==============\n",
    "if args.display == 'multilayer':\n",
    "    tensor_display = models.multilayer(\n",
    "        args.angular,\n",
    "        args.layers,\n",
    "        args.inph,\n",
    "        args.inpw,\n",
    "        args=args).to(device)\n",
    "else:\n",
    "    print('No valid display type chosen')\n",
    "    print('exiting')\n",
    "    exit(0)\n",
    "logging.info(\n",
    "    f\"Using the {args.display} display with {args.layers} layers and {args.rank} rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = utils.load_checkpoint(\n",
    "    args, models_list, optimizer, scheduler)\n",
    "global_step = state_dict['last_step']\n",
    "start_epoch = state_dict['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.build_dataset(\n",
    "    args.dataset,\n",
    "    args.data_path,\n",
    "    args,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Track moving average of loss values\n",
    "# test_meters = {name: utils.AverageMeter() for name in (\n",
    "#     [\"test_psnr\", \"test_ssim\", \"test_loss\", \"test_lpips\"])}\n",
    "# writer = SummaryWriter(\n",
    "#     log_dir=args.experiment_dir) if not args.no_visual else None\n",
    "# time_meters = utils.AverageMeter()\n",
    "\n",
    "# loss_fn_alex = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "\n",
    "# new save path will be near where the test data is\n",
    "# save_path = os.path.join(args.data_path, args.h5_file).split('/')[:-1]\n",
    "# save_path = os.path.join(*save_path)\n",
    "# expt_dir = args.restore_file.split('/')[-3]\n",
    "save_path = args.save_dir#os.path.join('/', save_path, expt_dir)\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)\n",
    "    print(f'removing the directory tree {save_path}')\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "print(save_path)\n",
    "\n",
    "for model in models_list:\n",
    "    model.eval()\n",
    "tensor_display.eval()\n",
    "\n",
    "# def compute_lpips_ssim_psnr(pred_lf, gt_lf, outputs):\n",
    "#     # pred_lf is [N, V, C, h,w]\n",
    "#     N, V, C, H, W = pred_lf.size()\n",
    "#     pred_lf = pred_lf.view(-1, C, H, W)\n",
    "#     gt_lf = gt_lf.view(-1, C, H, W)\n",
    "\n",
    "#     # compute lpips\n",
    "#     pred_lf_norm = 2 * pred_lf - 1.\n",
    "#     gt_lf_norm = 2 * gt_lf - 1.\n",
    "#     lpips_loss = loss_fn_alex(pred_lf_norm, gt_lf_norm).mean()\n",
    "#     outputs['lpips'].append(lpips_loss)\n",
    "\n",
    "    # compute ssim\n",
    "#     def tensor2np(tensor): \n",
    "#         return tensor.data.cpu(\n",
    "#     ).numpy().squeeze().transpose(0, 2, 3, 1)\n",
    "    \n",
    "#     pred_lf_np = tensor2np(pred_lf)\n",
    "#     gt_lf_np = tensor2np(gt_lf)\n",
    "\n",
    "#     totalssim = 0.\n",
    "#     for k in range(len(pred_lf_np)):\n",
    "#         totalssim += ssim(pred_lf_np[k, ...], gt_lf_np[k, ...],\n",
    "#                           multichannel=True, data_range=1.)\n",
    "#     totalssim /= len(pred_lf_np)\n",
    "#     outputs['ssim'].append(totalssim)\n",
    "\n",
    "#     # compute psnr\n",
    "#     mse = ((pred_lf_np - gt_lf_np)**2).mean()\n",
    "#     psnr = 20 * np.log10(1. / mse)\n",
    "#     outputs['psnr'].append(psnr)\n",
    "\n",
    "\n",
    "# test loader\n",
    "# for meter in test_meters.values():\n",
    "#     meter.reset()\n",
    "\n",
    "test_bar = utils.ProgressBar(test_loader)\n",
    "save_every = 1\n",
    "# metrics_file = open(f'{save_path}/metrics.txt', 'w')\n",
    "for sample_id, inputs in enumerate(test_bar):\n",
    "    ssim_vid = []\n",
    "    lpips_vid = []\n",
    "    with torch.no_grad():\n",
    "        outputs = {}\n",
    "        run_batch(inputs, outputs)\n",
    "        # outputs[\"pred_lf\"] will be a sequence of LF frames\n",
    "        # you just have to save them\n",
    "        # and also compute psnr; ssim and lpips\n",
    "        # which you can do in the run_batch fn itself\n",
    "        # test only with a batch size of 1\n",
    "        assert inputs['video'].size(0) == 1\n",
    "        if sample_id % save_every == 0:\n",
    "            # each video sequence will be saved in a separate directory\n",
    "            # each frame of the video sequence will be saved in a separate\n",
    "            # sub-directory\n",
    "            seq_save_path = f'{save_path}/seq_{sample_id:03d}'\n",
    "            os.makedirs(f'{save_path}/seq_{sample_id:03d}', exist_ok=True)\n",
    "\n",
    "            # then save the predicted light field\n",
    "            for t in range(len(outputs['pred_lf'])):\n",
    "                pred_lf_np = outputs['pred_lf'][t].data.cpu(\n",
    "                ).numpy().squeeze()\n",
    "                pred_lf_np = np.transpose(pred_lf_np, [0, 2, 3, 1])\n",
    "                pred_lf_np = (pred_lf_np - np.amin(pred_lf_np))/(np.amax(pred_lf_np) - np.amin(pred_lf_np))\n",
    "                save_lf_path = os.path.join(\n",
    "                    seq_save_path, f'pred_lf_{sample_id:02d}_{t:02d}.avi')\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                out = cv2.VideoWriter(\n",
    "                    save_lf_path, fourcc, 7, (args.inpw, args.inph))\n",
    "#                 print(pred_lf_np.shape)\n",
    "#                 print(args.inpw,args.inph)\n",
    "                for k in range(len(pred_lf_np)):\n",
    "                    out.write(np.uint8(pred_lf_np[k, ..., ::-1] * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ce4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         for metric in ['psnr', 'lpips', 'ssim']:\n",
    "#             mean_val = sum(outputs[metric]) / len(outputs[metric])\n",
    "#             outputs[metric] = mean_val\n",
    "#         test_meters[\"test_psnr\"].update(outputs['psnr'])\n",
    "#         test_meters[\"test_lpips\"].update(outputs['lpips'])\n",
    "#         test_meters[\"test_ssim\"].update(outputs['ssim'])\n",
    "#         metrics_text = f'For seq {sample_id:02d}: PSNR={outputs[\"psnr\"]:0.2f}; SSIM={outputs[\"ssim\"]:0.3f}; LPIPS={outputs[\"lpips\"]:0.3f}\\n'\n",
    "#         metrics_file.write(metrics_text)\n",
    "#         print(metrics_text)\n",
    "\n",
    "# if args.psnr:\n",
    "#     logging.info(\n",
    "#         f\"PSNR achieved on test data: {test_meters['test_psnr'].avg:0.3f}\")\n",
    "# metrics_text = f\"Dataset average: PSNR={test_meters['test_psnr'].avg:0.2f}; SSIM={test_meters['test_ssim'].avg:0.3f}; LPIPS={test_meters['test_lpips'].avg:0.3f}\\n\"\n",
    "# time_text = f'Average time taken is {time_meters.avg}\\n'\n",
    "# metrics_file.write(metrics_text)\n",
    "# metrics_file.write(time_text)\n",
    "# print(metrics_text)\n",
    "# metrics_file.close()\n",
    "\n",
    "\n",
    "# def get_args():\n",
    "#     parser = argparse.ArgumentParser(allow_abbrev=False)\n",
    "\n",
    "#     # Add data arguments\n",
    "#     parser.add_argument(\n",
    "#         \"--data-path\",\n",
    "#         default=\"/data/prasan/datasets/lfv_testFiles/\",\n",
    "#         help=\"path to data directory\")\n",
    "#     parser.add_argument(\n",
    "#         \"--h5-file\",\n",
    "#         default=\"lf_data.h5\",\n",
    "#         help=\"path to data directory\")\n",
    "#     parser.add_argument(\n",
    "#         \"--dataset\",\n",
    "#         default=\"dummy\",\n",
    "#         help=\"train dataset name\")\n",
    "#     parser.add_argument(\n",
    "#         \"--batch_size\",\n",
    "#         default=16,\n",
    "#         type=int,\n",
    "#         help=\"train batch size\")\n",
    "\n",
    "#     # Add model arguments\n",
    "#     parser.add_argument(\n",
    "#         \"--model\",\n",
    "#         default=\"unet_lf\",\n",
    "#         help=\"model architecture\")\n",
    "#     parser.add_argument(\n",
    "#         \"--flow-model\",\n",
    "#         default=\"unet_disp\",\n",
    "#         help=\"depth encoder network\")\n",
    "#     parser.add_argument(\n",
    "#         \"--disp-model\",\n",
    "#         default=\"unet_disp\",\n",
    "#         help=\"depth decoder network\")\n",
    "#     parser.add_argument(\n",
    "#         '--rank',\n",
    "#         type=int,\n",
    "#         default=3,\n",
    "#         help='rank of the light field decomposition')\n",
    "#     parser.add_argument(\n",
    "#         '--layers',\n",
    "#         type=int,\n",
    "#         default=3,\n",
    "#         help='number of layers in the LF display')\n",
    "#     parser.add_argument(\n",
    "#         '--inph',\n",
    "#         type=int,\n",
    "#         default=128,\n",
    "#         help='height of input image')\n",
    "#     parser.add_argument(\n",
    "#         '--inpw',\n",
    "#         type=int,\n",
    "#         default=128,\n",
    "#         help='width of input image')\n",
    "#     parser.add_argument(\n",
    "#         '--angular',\n",
    "#         type=int,\n",
    "#         default=7,\n",
    "#         help='angular resolution of the light field')\n",
    "#     parser.add_argument(\n",
    "#         '--display',\n",
    "#         type=str,\n",
    "#         default=\"angular\",\n",
    "#         choices=(\n",
    "#             'angular',\n",
    "#             'multilayer'),\n",
    "#         help='type of display to use (angular,multilayer)')\n",
    "#     parser.add_argument(\n",
    "#         '--seq-len',\n",
    "#         type=int,\n",
    "#         default=5,\n",
    "#         help='video sequence length')\n",
    "\n",
    "#     parser.add_argument(\n",
    "#         \"--gpu\",\n",
    "#         default=\"0\",\n",
    "#         help=\"which gpu to use for training\")\n",
    "\n",
    "#     # Add loss parameters\n",
    "#     parser.add_argument(\n",
    "#         \"--lambda_sm\",\n",
    "#         default=0.01,\n",
    "#         type=float,\n",
    "#         help=\"how much to weight the TV smoothness loss\")\n",
    "#     parser.add_argument(\n",
    "#         \"--lambda-temp\",\n",
    "#         default=0.01,\n",
    "#         type=float,\n",
    "#         help=\"how much to weight the TV smoothness loss\")\n",
    "#     parser.add_argument(\n",
    "#         \"--metric\",\n",
    "#         default='l2',\n",
    "#         type=str,\n",
    "#         help=\"whether to use perceptual or l2 metric\")\n",
    "#     parser.add_argument(\n",
    "#         \"--psnr\",\n",
    "#         action=\"store_true\",\n",
    "#         help=\"if true,then compute PSNR from GT\")\n",
    "\n",
    "#     # Add optimization arguments\n",
    "#     parser.add_argument(\"--lr\", default=1e-4, type=float, help=\"learning rate\")\n",
    "#     parser.add_argument(\n",
    "#         \"--num-epochs\",\n",
    "#         default=500,\n",
    "#         type=int,\n",
    "#         help=\"force stop training at specified epoch\")\n",
    "#     parser.add_argument(\n",
    "#         \"--patience\",\n",
    "#         default=5,\n",
    "#         type=int,\n",
    "#         help=\" Number of epochs with no improvement after which learning rate will be reduced.\")\n",
    "#     parser.add_argument(\n",
    "#         \"--valid-interval\",\n",
    "#         default=1,\n",
    "#         type=int,\n",
    "#         help=\"evaluate every N epochs\")\n",
    "#     parser.add_argument(\n",
    "#         \"--save-interval\",\n",
    "#         default=1,\n",
    "#         type=int,\n",
    "#         help=\"save a checkpoint every N steps\")\n",
    "\n",
    "#     parser.add_argument(\n",
    "#         \"--test\",\n",
    "#         action=\"store_true\",\n",
    "#         help=\"if true, then use the RGB test data\")\n",
    "#     # Parse twice as model arguments are not known the first time\n",
    "#     # not really parsing twice; Just adding more arguments to the model\n",
    "#     parser = add_logging_arguments(parser)\n",
    "#     # parsing only the known arguments; arguments that are not passed are\n",
    "#     # ignored\n",
    "#     args, _ = parser.parse_known_args()\n",
    "#     return args\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     args = get_args()\n",
    "#     # os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#     # os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "#     print(f\"set gpu device to {args.gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a1e268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
